INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'nym_embeddings/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'nym_embeddings/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'nym_embeddings/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'nym_embeddings/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = nym_embeddings/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 449, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 449, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = nym_embeddings/wikirr_ke.amplimodel
INFO - Will load model nym_embeddings/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 449, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 449
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = BIOUL
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = True
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1074465
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2492.316
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'nym_embeddings/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'nym_embeddings/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'nym_embeddings/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'nym_embeddings/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = nym_embeddings/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = nym_embeddings/wikirr_ke.amplimodel
INFO - Will load model nym_embeddings/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = BIOUL
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = True
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'nym_embeddings/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'nym_embeddings/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'nym_embeddings/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'nym_embeddings/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = nym_embeddings/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'nym_embeddings/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = nym_embeddings/wikirr_ke.amplimodel
INFO - Will load model nym_embeddings/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = BIOUL
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = True
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
WARNING - /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "

INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = BIOUL
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = True
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1037025
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2410.22
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = BIOUL
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = True
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1037025
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2410.324
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = BIOUL
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = True
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1037025
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2410.0
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - precision-overall  |     0.000  |     0.000
INFO - loss               |  3289.308  |  2178.456
INFO - recall-overall     |     0.000  |     0.000
INFO - cpu_memory_MB      |  2410.000  |       N/A
INFO - f1-measure-overall |     0.000  |     0.000
INFO - accuracy3          |     0.160  |     0.161
INFO - accuracy           |     0.160  |     0.161
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:11:06.105680
INFO - Estimated training time remaining: 1 day, 12:49:15
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 24082.468
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = BIOUL
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1037025
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2410.032
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - loss               |  3289.308  |  2178.456
INFO - recall-overall     |     0.000  |     0.000
INFO - cpu_memory_MB      |  2410.032  |       N/A
INFO - precision-overall  |     0.000  |     0.000
INFO - accuracy           |     0.160  |     0.161
INFO - accuracy3          |     0.160  |     0.161
INFO - f1-measure-overall |     0.000  |     0.000
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:11:05.259391
INFO - Estimated training time remaining: 1 day, 12:46:26
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23941.524
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIO', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIO', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = BIO
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1037025
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.54
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.804
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - recall-overall     |     0.001  |     0.000
INFO - precision-overall  |     0.003  |     0.000
INFO - cpu_memory_MB      |  2409.804  |       N/A
INFO - accuracy3          |     0.201  |     0.161
INFO - loss               |  2287.023  |  1325.904
INFO - accuracy           |     0.201  |     0.161
INFO - f1-measure-overall |     0.002  |     0.000
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:11:03.319268
INFO - Estimated training time remaining: 1 day, 12:40:00
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23965.956
INFO - Training
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Will load model ./models/wikirr_ke.amplimodel.
INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 10
INFO - margin : 0.5
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 1e-05
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.001
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 5
INFO - margin : 1
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 0.1
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 5
INFO - margin : 1
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 0.1
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.01
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.0007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.824
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.150  |     0.160
INFO - f1-measure-overall |     0.000  |     0.000
INFO - precision-overall  |     0.000  |     0.000
INFO - recall-overall     |     0.000  |     0.000
INFO - accuracy3          |     0.150  |     0.160
INFO - cpu_memory_MB      |  2409.824  |       N/A
INFO - loss               |  3779.246  |  1794.749
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:10:50.766260
INFO - Estimated training time remaining: 1 day, 11:58:22
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23806.936
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.188  |     0.160
INFO - f1-measure-overall |     0.001  |     0.000
INFO - precision-overall  |     0.007  |     0.000
INFO - recall-overall     |     0.001  |     0.000
INFO - accuracy3          |     0.188  |     0.160
INFO - cpu_memory_MB      |  23806.936  |       N/A
INFO - loss               |  1766.693  |  1546.580
INFO - Epoch duration: 0:09:38.539371
INFO - Estimated training time remaining: 1 day, 9:48:21
INFO - Epoch 2/199
INFO - Peak CPU memory usage MB: 24413.644
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.202  |     0.253
INFO - f1-measure-overall |     0.002  |     0.017
INFO - precision-overall  |     0.007  |     0.048
INFO - recall-overall     |     0.001  |     0.010
INFO - accuracy3          |     0.202  |     0.253
INFO - cpu_memory_MB      |  24413.644  |       N/A
INFO - loss               |  1624.021  |  1469.982
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:09:49.295130
INFO - Estimated training time remaining: 1 day, 9:10:21
INFO - Epoch 3/199
INFO - Peak CPU memory usage MB: 24674.804
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.233  |     0.255
INFO - f1-measure-overall |     0.013  |     0.015
INFO - precision-overall  |     0.034  |     0.039
INFO - recall-overall     |     0.008  |     0.009
INFO - accuracy3          |     0.233  |     0.255
INFO - cpu_memory_MB      |  24674.804  |       N/A
INFO - loss               |  1559.275  |  1425.339
INFO - Epoch duration: 0:09:49.388968
INFO - Estimated training time remaining: 1 day, 8:46:31
INFO - Epoch 4/199
INFO - Peak CPU memory usage MB: 24683.452
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.243  |     0.247
INFO - f1-measure-overall |     0.015  |     0.012
INFO - precision-overall  |     0.040  |     0.043
INFO - recall-overall     |     0.010  |     0.007
INFO - accuracy3          |     0.243  |     0.247
INFO - cpu_memory_MB      |  24683.452  |       N/A
INFO - loss               |  1499.262  |  1379.163
INFO - Epoch duration: 0:09:52.744031
INFO - Estimated training time remaining: 1 day, 8:30:28
INFO - Epoch 5/199
INFO - Peak CPU memory usage MB: 24813.22
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.245  |     0.267
INFO - f1-measure-overall |     0.018  |     0.014
INFO - precision-overall  |     0.043  |     0.010
INFO - recall-overall     |     0.011  |     0.023
INFO - accuracy3          |     0.245  |     0.267
INFO - cpu_memory_MB      |  24813.220  |       N/A
INFO - loss               |  1167.193  |  -6705.947
INFO - Epoch duration: 0:09:50.659585
INFO - Estimated training time remaining: 1 day, 8:15:21
INFO - Epoch 6/199
INFO - Peak CPU memory usage MB: 24909.64
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 5
INFO - margin : 1
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 0.1
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.01
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.912
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - precision-overall  |     0.003  |     0.000
INFO - f1-measure-overall |     0.002  |     0.000
INFO - cpu_memory_MB      |  2409.912  |       N/A
INFO - recall-overall     |     0.001  |     0.000
INFO - accuracy           |     0.193  |     0.160
INFO - accuracy3          |     0.193  |     0.160
INFO - loss               |  3014.883  |  1327.539
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:10:49.222976
INFO - Estimated training time remaining: 1 day, 11:53:15
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23842.944
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 5
INFO - margin : 1
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 0.1
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.01
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.864
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy3          |     0.193  |     0.160
INFO - accuracy           |     0.193  |     0.160
INFO - cpu_memory_MB      |  2409.864  |       N/A
INFO - f1-measure-overall |     0.002  |     0.000
INFO - recall-overall     |     0.001  |     0.000
INFO - precision-overall  |     0.003  |     0.000
INFO - loss               |  3014.883  |  1327.539
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:10:54.140694
INFO - Estimated training time remaining: 1 day, 12:09:34
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23845.92
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'antonyms': {'lowercase_tokens': True, 'type': 'single_id'}, 'cohyponyms': {'lowercase_tokens': True, 'type': 'single_id'}, 'elmo': {'type': 'elmo_characters'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'antonyms': {'lowercase_tokens': True, 'type': 'single_id'}, 'cohyponyms': {'lowercase_tokens': True, 'type': 'single_id'}, 'elmo': {'type': 'elmo_characters'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'lowercase_tokens': True, 'type': 'single_id'} and extras set()
INFO - dataset_reader.token_indexers.antonyms.type = single_id
INFO - instantiating class <class 'allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer'> from params {'lowercase_tokens': True} and extras set()
INFO - dataset_reader.token_indexers.antonyms.namespace = tokens
INFO - dataset_reader.token_indexers.antonyms.lowercase_tokens = True
INFO - dataset_reader.token_indexers.antonyms.start_tokens = None
INFO - dataset_reader.token_indexers.antonyms.end_tokens = None
INFO - dataset_reader.token_indexers.antonyms.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'lowercase_tokens': True, 'type': 'single_id'} and extras set()
INFO - dataset_reader.token_indexers.cohyponyms.type = single_id
INFO - instantiating class <class 'allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer'> from params {'lowercase_tokens': True} and extras set()
INFO - dataset_reader.token_indexers.cohyponyms.namespace = tokens
INFO - dataset_reader.token_indexers.cohyponyms.lowercase_tokens = True
INFO - dataset_reader.token_indexers.cohyponyms.start_tokens = None
INFO - dataset_reader.token_indexers.cohyponyms.end_tokens = None
INFO - dataset_reader.token_indexers.cohyponyms.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./corpus_data/train.txt
INFO - Reading training data from ./corpus_data/train.txt
INFO - Reading instances from lines in file at: ./corpus_data/train.txt
INFO - validation_data_path = ./corpus_data/valid.txt
INFO - Reading validation data from ./corpus_data/valid.txt
INFO - Reading instances from lines in file at: ./corpus_data/valid.txt
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 349, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'antonyms': {'projection_dim': 20, 'type': 'xnym_embedder', 'xnyms': 'antonyms'}, 'cohyponyms': {'projection_dim': 20, 'type': 'xnym_embedder', 'xnyms': 'cohyponyms'}, 'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 349, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'antonyms': {'projection_dim': 20, 'type': 'xnym_embedder', 'xnyms': 'antonyms'}, 'cohyponyms': {'projection_dim': 20, 'type': 'xnym_embedder', 'xnyms': 'cohyponyms'}, 'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'antonyms': {'projection_dim': 20, 'type': 'xnym_embedder', 'xnyms': 'antonyms'}, 'cohyponyms': {'projection_dim': 20, 'type': 'xnym_embedder', 'xnyms': 'cohyponyms'}, 'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'projection_dim': 20, 'type': 'xnym_embedder', 'xnyms': 'antonyms'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.antonyms.type = xnym_embedder
INFO - instantiating class <class 'xnym_embeddings.xnym_embeddings.XnymEmbedder'> from params {'projection_dim': 20, 'xnyms': 'antonyms'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.antonyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.antonyms.xnyms = antonyms
INFO - model.text_field_embedder.token_embedders.antonyms.normalize = True
INFO - model.text_field_embedder.token_embedders.antonyms.sparse = True
INFO - model.text_field_embedder.token_embedders.antonyms.parallelize = False
INFO - model.text_field_embedder.token_embedders.antonyms.numerize_dict = True
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'projection_dim': 20, 'type': 'xnym_embedder', 'xnyms': 'cohyponyms'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.cohyponyms.type = xnym_embedder
INFO - instantiating class <class 'xnym_embeddings.xnym_embeddings.XnymEmbedder'> from params {'projection_dim': 20, 'xnyms': 'cohyponyms'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.cohyponyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.cohyponyms.xnyms = cohyponyms
INFO - model.text_field_embedder.token_embedders.cohyponyms.normalize = True
INFO - model.text_field_embedder.token_embedders.cohyponyms.sparse = True
INFO - model.text_field_embedder.token_embedders.cohyponyms.parallelize = False
INFO - model.text_field_embedder.token_embedders.cohyponyms.numerize_dict = True
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 349, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 349
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - model.label_encoding = BIOUL
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = True
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 100
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 807645
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/99
INFO - Peak CPU memory usage MB: 2370.192
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - cpu_memory_MB      |  2370.192  |       N/A
INFO - accuracy3          |     0.492  |     0.537
INFO - recall-overall     |     0.013  |     0.197
INFO - accuracy           |     0.469  |     0.515
INFO - f1-measure-overall |     0.023  |     0.242
INFO - precision-overall  |     0.101  |     0.314
INFO - loss               |  3587.808  |  2636.050
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/difference_stacked_birectional_lstm3.config//best.th'.
INFO - Epoch duration: 0:13:03.644744
INFO - Estimated training time remaining: 21:33:00
INFO - Epoch 1/99
INFO - Peak CPU memory usage MB: 16376.272
INFO - Training
INFO - Validating
INFO - Training interrupted by the user. Attempting to create a model archive using the current best epoch weights.
INFO - archiving weights and vocabulary to ./output/experiment_configs/difference_stacked_birectional_lstm3.config/model.tar.gz
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'BIOUL', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = BIOUL
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 309, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 176, 196, 216, 196, 176, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'calculate_span_f1': True, 'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 309, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 176, 196, 216, 196, 176, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'BIOUL', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 309, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 309
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 176, 196, 216, 196, 176, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 176, 196, 216, 196, 176, 156]
INFO - model.feedforward.hidden_dims = [156, 176, 196, 216, 196, 176, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = BIOUL
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = True
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1006165
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.003
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2354.632
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 5
INFO - margin : 1
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 0.1
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.01
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.716
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - recall-overall     |     0.001  |     0.000
INFO - accuracy           |     0.198  |     0.160
INFO - precision-overall  |     0.002  |     0.000
INFO - accuracy3          |     0.198  |     0.160
INFO - loss               |  3404.969  |  1352.998
INFO - f1-measure-overall |     0.001  |     0.000
INFO - cpu_memory_MB      |  2409.716  |       N/A
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:14:28.961776
INFO - Estimated training time remaining: 2 days, 0:02:03
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23999.14
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 5
INFO - margin : 1
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 0.1
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.01
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.972
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - precision-overall  |     0.002  |     0.000
INFO - cpu_memory_MB      |  2409.972  |       N/A
INFO - recall-overall     |     0.001  |     0.000
INFO - accuracy3          |     0.187  |     0.160
INFO - loss               |  2396.887  |  1312.713
INFO - accuracy           |     0.187  |     0.160
INFO - f1-measure-overall |     0.001  |     0.000
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:14:03.514531
INFO - Estimated training time remaining: 1 day, 22:37:39
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23748.84
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : pairwise
INFO - eta : 5
INFO - margin : 1
INFO - 
------ Regularizer -----
INFO - Name : LP
INFO - lambda : 0.1
INFO - p : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.01
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.896
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - cpu_memory_MB      |  2409.896  |       N/A
INFO - loss               |  2396.887  |  1312.713
INFO - accuracy3          |     0.187  |     0.160
INFO - accuracy           |     0.187  |     0.160
INFO - f1-measure-overall |     0.001  |     0.000
INFO - recall-overall     |     0.001  |     0.000
INFO - precision-overall  |     0.002  |     0.000
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:14:00.038434
INFO - Estimated training time remaining: 1 day, 22:26:07
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23964.984
INFO - Training
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.608
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy3          |     0.202  |     0.167
INFO - recall-overall     |     0.001  |     0.001
INFO - precision-overall  |     0.002  |     0.067
INFO - accuracy           |     0.202  |     0.167
INFO - cpu_memory_MB      |  2409.608  |       N/A
INFO - loss               |  2285.415  |  1286.008
INFO - f1-measure-overall |     0.001  |     0.001
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:13:51.699350
INFO - Estimated training time remaining: 1 day, 21:58:28
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23806.508
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy3          |     0.203  |     0.262
INFO - recall-overall     |     0.016  |     0.016
INFO - precision-overall  |     0.042  |     0.028
INFO - accuracy           |     0.203  |     0.262
INFO - cpu_memory_MB      |  23806.508  |       N/A
INFO - loss               |  -968.507  |  -174290.235
INFO - f1-measure-overall |     0.023  |     0.021
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:26:16.829405
INFO - Estimated training time remaining: 2 days, 18:14:04
INFO - Epoch 2/199
INFO - Peak CPU memory usage MB: 24403.232
INFO - Training
INFO - Training interrupted by the user. Attempting to create a model archive using the current best epoch weights.
INFO - archiving weights and vocabulary to ./output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config/model.tar.gz
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.888
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.181  |     0.087
INFO - cpu_memory_MB      |  2409.888  |       N/A
INFO - accuracy3          |     0.181  |     0.087
INFO - precision-overall  |     0.002  |     0.009
INFO - recall-overall     |     0.001  |     0.051
INFO - loss               |  2450.817  |    89.474
INFO - f1-measure-overall |     0.001  |     0.016
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:14:06.708596
INFO - Estimated training time remaining: 1 day, 22:48:15
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23815.672
INFO - Training
INFO - Training interrupted by the user. Attempting to create a model archive using the current best epoch weights.
INFO - archiving weights and vocabulary to ./output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config/model.tar.gz
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.672
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - cpu_memory_MB      |  2409.672  |       N/A
INFO - f1-measure-overall |     0.001  |     0.000
INFO - recall-overall     |     0.001  |     0.000
INFO - accuracy3          |     0.200  |     0.162
INFO - loss               |  2284.526  |  1308.300
INFO - precision-overall  |     0.002  |     0.000
INFO - accuracy           |     0.200  |     0.162
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:14:05.653733
INFO - Estimated training time remaining: 1 day, 22:44:45
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23814.596
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - cpu_memory_MB      |  23814.596  |       N/A
INFO - f1-measure-overall |     0.020  |     0.000
INFO - recall-overall     |     0.016  |     0.000
INFO - accuracy3          |     0.202  |     0.134
INFO - loss               |  -1981044.035  |  -129126942.222
INFO - precision-overall  |     0.026  |     0.000
INFO - accuracy           |     0.202  |     0.134
INFO - Epoch duration: 0:17:33.628934
INFO - Estimated training time remaining: 2 days, 4:13:49
INFO - Epoch 2/199
INFO - Peak CPU memory usage MB: 24379.536
INFO - Training
INFO - Training interrupted by the user. Attempting to create a model archive using the current best epoch weights.
INFO - archiving weights and vocabulary to ./output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config/model.tar.gz
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.476
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.200  |     0.162
INFO - recall-overall     |     0.001  |     0.000
INFO - cpu_memory_MB      |  2409.476  |       N/A
INFO - precision-overall  |     0.002  |     0.000
INFO - loss               |  2284.526  |  1308.300
INFO - f1-measure-overall |     0.001  |     0.000
INFO - accuracy3          |     0.200  |     0.162
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:14:03.487778
INFO - Estimated training time remaining: 1 day, 22:37:34
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23886.492
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.202  |     0.134
INFO - recall-overall     |     0.016  |     0.000
INFO - cpu_memory_MB      |  23886.492  |       N/A
INFO - precision-overall  |     0.026  |     0.000
INFO - loss               |  -1981044.035  |  -129126942.222
INFO - f1-measure-overall |     0.020  |     0.000
INFO - accuracy3          |     0.202  |     0.134
INFO - Epoch duration: 0:12:39.039313
INFO - Estimated training time remaining: 1 day, 20:04:10
INFO - Epoch 2/199
INFO - Peak CPU memory usage MB: 24230.112
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.071  |     0.000
INFO - recall-overall     |     0.017  |     0.000
INFO - cpu_memory_MB      |  24230.112  |       N/A
INFO - precision-overall  |     0.009  |     0.000
INFO - loss               |  -6384603165031.529  |  -87267974345159.109
INFO - f1-measure-overall |     0.012  |     0.000
INFO - accuracy3          |     0.071  |     0.000
INFO - Epoch duration: 0:12:53.670894
INFO - Estimated training time remaining: 1 day, 19:20:37
INFO - Epoch 3/199
INFO - Peak CPU memory usage MB: 24446.336
INFO - Training
INFO - Training interrupted by the user. Attempting to create a model archive using the current best epoch weights.
INFO - archiving weights and vocabulary to ./output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config/model.tar.gz
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035879
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2410.476
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.200  |     0.162
INFO - precision-overall  |     0.002  |     0.000
INFO - loss               |  2284.526  |  1308.300
INFO - f1-measure-overall |     0.001  |     0.000
INFO - cpu_memory_MB      |  2410.476  |       N/A
INFO - recall-overall     |     0.001  |     0.000
INFO - accuracy3          |     0.200  |     0.162
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:14:03.991615
INFO - Estimated training time remaining: 1 day, 22:39:14
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23946.496
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, train, validation will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1035861
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2409.444
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - precision-overall  |     0.004  |     0.000
INFO - cpu_memory_MB      |  2409.444  |       N/A
INFO - loss               |  2645.611  |  1362.970
INFO - accuracy           |     0.174  |     0.162
INFO - accuracy3          |     0.174  |     0.162
INFO - recall-overall     |     0.003  |     0.000
INFO - f1-measure-overall |     0.004  |     0.000
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:14:00.334818
INFO - Estimated training time remaining: 1 day, 22:27:06
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23763.596
INFO - Training
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 409, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 409
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - random_seed = 13370
INFO - numpy_seed = 1337
INFO - pytorch_seed = 133
INFO - Pytorch version: 1.2.0
INFO - evaluate_on_test = False
INFO - validation_dataset_reader = None
INFO - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}, 'type': 'conll2003'} and extras set()
INFO - dataset_reader.type = conll2003
INFO - instantiating class <class 'allennlp.data.dataset_readers.conll2003.Conll2003DatasetReader'> from params {'coding_scheme': 'IOB1', 'tag_label': 'ner', 'token_indexers': {'elmo': {'type': 'elmo_characters'}, 'nyms': {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'}, 'token_characters': {'min_padding_length': 3, 'type': 'characters'}}} and extras set()
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'type': 'elmo_characters'} and extras set()
INFO - dataset_reader.token_indexers.elmo.type = elmo_characters
INFO - instantiating class <class 'allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer'> from params {} and extras set()
INFO - dataset_reader.token_indexers.elmo.namespace = elmo_characters
INFO - dataset_reader.token_indexers.elmo.tokens_to_add = None
INFO - dataset_reader.token_indexers.elmo.token_min_padding_length = 0
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys', 'type': 'synset_indexer'} and extras set()
INFO - dataset_reader.token_indexers.nyms.type = synset_indexer
INFO - instantiating class <class 'nym_embeddings.synset_indexer.SynsetIndexer'> from params {'key_path': 'models/wikirr_ke.wnkeys'} and extras set()
INFO - dataset_reader.token_indexers.nyms.namespace = synset_indexer
INFO - dataset_reader.token_indexers.nyms.token_min_padding_length = 0
INFO - dataset_reader.token_indexers.nyms.key_path = models/wikirr_ke.wnkeys
INFO - instantiating class <class 'allennlp.data.token_indexers.token_indexer.TokenIndexer'> from params {'min_padding_length': 3, 'type': 'characters'} and extras set()
INFO - dataset_reader.token_indexers.token_characters.type = characters
INFO - instantiating class <class 'allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer'> from params {'min_padding_length': 3} and extras set()
INFO - dataset_reader.token_indexers.token_characters.namespace = token_characters
INFO - dataset_reader.token_indexers.token_characters.start_tokens = None
INFO - dataset_reader.token_indexers.token_characters.end_tokens = None
INFO - dataset_reader.token_indexers.token_characters.min_padding_length = 3
INFO - dataset_reader.token_indexers.token_characters.token_min_padding_length = 0
INFO - dataset_reader.tag_label = ner
INFO - dataset_reader.feature_labels = ()
INFO - dataset_reader.lazy = False
INFO - dataset_reader.coding_scheme = IOB1
INFO - dataset_reader.label_namespace = labels
INFO - train_data_path = ./manual_corpus/train.conll3
INFO - Reading training data from ./manual_corpus/train.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/train.conll3
INFO - validation_data_path = ./manual_corpus/test.conll3
INFO - Reading validation data from ./manual_corpus/test.conll3
INFO - Reading instances from lines in file at: ./manual_corpus/test.conll3
INFO - test_data_path = None
INFO - From dataset instances, validation, train will be considered for vocabulary creation.
INFO - vocabulary.type = None
INFO - vocabulary.extend = False
INFO - vocabulary.directory_path = None
INFO - vocabulary.min_count = None
INFO - vocabulary.max_vocab_size = None
INFO - vocabulary.non_padded_namespaces = ('*tags', '*labels')
INFO - vocabulary.pretrained_files = {}
INFO - vocabulary.min_pretrained_embeddings = None
INFO - vocabulary.only_include_pretrained_words = False
INFO - vocabulary.tokens_to_add = None
INFO - Fitting token dictionary from dataset.
INFO - instantiating class <class 'allennlp.models.model.Model'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 379, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}, 'type': 'attentive_crf_tagger'} and extras {'vocab'}
INFO - model.type = attentive_crf_tagger
INFO - instantiating class <class 'attentivecrftagger.attentivecrftagger.AttentiveCrfTagger'> from params {'constrain_crf_decoding': True, 'dropout': 0.5, 'encoder': {'hidden_size': 78, 'input_size': 379, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'}, 'feedforward': {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7}, 'include_start_end_transitions': False, 'label_encoding': 'IOB1', 'regularizer': [['scalar_parameters', {'alpha': 0.1, 'type': 'l2'}]], 'text_field_embedder': {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}}} and extras {'vocab'}
INFO - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'elmo': {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'}, 'nyms': {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'}, 'token_characters': {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'}}} and extras {'vocab'}
INFO - model.text_field_embedder.type = basic
INFO - model.text_field_embedder.embedder_to_indexer_map = None
INFO - model.text_field_embedder.allow_unmatched_keys = False
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'do_layer_norm': False, 'dropout': 0, 'options_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_options.json', 'type': 'elmo_token_embedder', 'weight_file': 'models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.elmo.type = elmo_token_embedder
INFO - model.text_field_embedder.token_embedders.elmo.options_file = models/elmo_2x1024_128_2048cnn_1xhighway_options.json
INFO - model.text_field_embedder.token_embedders.elmo.weight_file = models/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5
INFO - model.text_field_embedder.token_embedders.elmo.requires_grad = False
INFO - model.text_field_embedder.token_embedders.elmo.do_layer_norm = False
INFO - model.text_field_embedder.token_embedders.elmo.dropout = 0
INFO - model.text_field_embedder.token_embedders.elmo.namespace_to_cache = None
INFO - model.text_field_embedder.token_embedders.elmo.projection_dim = None
INFO - model.text_field_embedder.token_embedders.elmo.scalar_mix_parameters = None
INFO - Initializing ELMo
INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20, 'type': 'nym_embedder'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.type = nym_embedder
INFO - instantiating class <class 'nym_embeddings.nym_embeddings.NymEmbedder'> from params {'model_path': 'models/wikirr_ke.amplimodel', 'projection_dim': 20} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.nyms.projection_dim = 20
INFO - model.text_field_embedder.token_embedders.nyms.model_path = models/wikirr_ke.amplimodel
INFO - model.text_field_embedder.token_embedders.nyms.ignore_oov = True
INFO - Will load model models/wikirr_ke.amplimodel.
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:262: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:265: The name tf.random.set_random_seed is deprecated. Please use tf.compat.v1.random.set_random_seed instead.

INFO - 
--------- Loss ---------
INFO - Name : nll
INFO - eta : 2
INFO - 
------ Optimizer -----
INFO - Name : adam
INFO - lr : 0.0005
INFO - 
------ Initializer -----
INFO - Name : xavier
INFO - uniform : False
WARNING - From /roedel/home/finn/ai-difference/venv/lib/python3.7/site-packages/ampligraph/latent_features/models.py:329: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

INFO - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'embedding': {'embedding_dim': 9}, 'encoder': {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'}, 'type': 'character_encoding'} and extras {'vocab'}
INFO - model.text_field_embedder.token_embedders.token_characters.type = character_encoding
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.num_embeddings = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.vocab_namespace = token_characters
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.pretrained_file = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.projection_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.trainable = True
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.padding_index = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.max_norm = None
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.norm_type = 2.0
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.scale_grad_by_freq = False
INFO - model.text_field_embedder.token_embedders.token_characters.embedding.sparse = False
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.seq2vec_encoder.Seq2VecEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53, 'type': 'cnn'} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.type = cnn
INFO - instantiating class <class 'allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder'> from params {'conv_layer_activation': 'relu', 'embedding_dim': 9, 'ngram_filter_sizes': [3], 'num_filters': 53} and extras set()
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.embedding_dim = 9
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.num_filters = 53
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.ngram_filter_sizes = [3]
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.conv_layer_activation = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.text_field_embedder.token_embedders.token_characters.encoder.output_dim = None
INFO - model.text_field_embedder.token_embedders.token_characters.dropout = 0.0
INFO - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'hidden_size': 78, 'input_size': 379, 'num_layers': 3, 'type': 'stacked_bidirectional_lstm'} and extras {'vocab'}
INFO - model.encoder.type = stacked_bidirectional_lstm
INFO - model.encoder.batch_first = True
INFO - model.encoder.stateful = False
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - model.encoder.hidden_size = 78
INFO - model.encoder.input_size = 379
INFO - model.encoder.num_layers = 3
INFO - model.label_namespace = labels
INFO - instantiating class <class 'allennlp.modules.feedforward.FeedForward'> from params {'activations': 'relu', 'hidden_dims': [156, 156, 156, 156, 156, 156, 156], 'input_dim': 156, 'num_layers': 7} and extras {'vocab'}
INFO - model.feedforward.input_dim = 156
INFO - model.feedforward.num_layers = 7
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.hidden_dims = [156, 156, 156, 156, 156, 156, 156]
INFO - model.feedforward.activations = relu
INFO - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>
INFO - model.feedforward.dropout = 0.0
INFO - model.label_encoding = IOB1
INFO - model.include_start_end_transitions = False
INFO - model.attention = None
INFO - model.constrain_crf_decoding = True
INFO - model.calculate_span_f1 = None
INFO - model.dropout = 0.5
INFO - model.verbose_metrics = False
INFO - model.regularizer.0.1.type = l2
INFO - instantiating registered subclass l2 of <class 'allennlp.nn.regularizers.regularizer.Regularizer'>
INFO - Initializing parameters
INFO - Done initializing parameters; the following parameters are using their default initialization from their code
INFO -    _feedforward._linear_layers.0.bias
INFO -    _feedforward._linear_layers.0.weight
INFO -    _feedforward._linear_layers.1.bias
INFO -    _feedforward._linear_layers.1.weight
INFO -    _feedforward._linear_layers.2.bias
INFO -    _feedforward._linear_layers.2.weight
INFO -    _feedforward._linear_layers.3.bias
INFO -    _feedforward._linear_layers.3.weight
INFO -    _feedforward._linear_layers.4.bias
INFO -    _feedforward._linear_layers.4.weight
INFO -    _feedforward._linear_layers.5.bias
INFO -    _feedforward._linear_layers.5.weight
INFO -    _feedforward._linear_layers.6.bias
INFO -    _feedforward._linear_layers.6.weight
INFO -    crf._constraint_mask
INFO -    crf.transitions
INFO -    encoder._module.backward_layer_0.input_linearity.weight
INFO -    encoder._module.backward_layer_0.state_linearity.bias
INFO -    encoder._module.backward_layer_0.state_linearity.weight
INFO -    encoder._module.backward_layer_1.input_linearity.weight
INFO -    encoder._module.backward_layer_1.state_linearity.bias
INFO -    encoder._module.backward_layer_1.state_linearity.weight
INFO -    encoder._module.backward_layer_2.input_linearity.weight
INFO -    encoder._module.backward_layer_2.state_linearity.bias
INFO -    encoder._module.backward_layer_2.state_linearity.weight
INFO -    encoder._module.forward_layer_0.input_linearity.weight
INFO -    encoder._module.forward_layer_0.state_linearity.bias
INFO -    encoder._module.forward_layer_0.state_linearity.weight
INFO -    encoder._module.forward_layer_1.input_linearity.weight
INFO -    encoder._module.forward_layer_1.state_linearity.bias
INFO -    encoder._module.forward_layer_1.state_linearity.weight
INFO -    encoder._module.forward_layer_2.input_linearity.weight
INFO -    encoder._module.forward_layer_2.state_linearity.bias
INFO -    encoder._module.forward_layer_2.state_linearity.weight
INFO -    tag_projection_layer._module.bias
INFO -    tag_projection_layer._module.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO -    text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO -    text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO -    text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO -    text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 64, 'type': 'basic'} and extras set()
INFO - iterator.type = basic
INFO - instantiating class <class 'allennlp.data.iterators.basic_iterator.BasicIterator'> from params {'batch_size': 64} and extras set()
INFO - iterator.batch_size = 64
INFO - iterator.instances_per_epoch = None
INFO - iterator.max_instances_in_memory = None
INFO - iterator.cache_instances = False
INFO - iterator.track_epoch = False
INFO - iterator.maximum_samples_per_batch = None
INFO - validation_iterator = None
INFO - trainer.no_grad = ()
INFO - Following parameters are Frozen  (without gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._char_embedding_weights
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_1.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_2.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_3.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_4.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_5.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder.char_conv_6.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._highways._layers.0.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._token_embedder._projection.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_0.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.forward_layer_1.state_projection.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.input_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.weight
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_linearity.bias
INFO - text_field_embedder.token_embedder_elmo._elmo._elmo_lstm._elmo_lstm.backward_layer_1.state_projection.weight
INFO - crf._constraint_mask
INFO - Following parameters are Tunable (with gradient):
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.gamma
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.0
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.1
INFO - text_field_embedder.token_embedder_elmo._elmo.scalar_mix_0.scalar_parameters.2
INFO - text_field_embedder.token_embedder_token_characters._embedding._module.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight
INFO - text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias
INFO - encoder._module.forward_layer_0.input_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.weight
INFO - encoder._module.forward_layer_0.state_linearity.bias
INFO - encoder._module.backward_layer_0.input_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.weight
INFO - encoder._module.backward_layer_0.state_linearity.bias
INFO - encoder._module.forward_layer_1.input_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.weight
INFO - encoder._module.forward_layer_1.state_linearity.bias
INFO - encoder._module.backward_layer_1.input_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.weight
INFO - encoder._module.backward_layer_1.state_linearity.bias
INFO - encoder._module.forward_layer_2.input_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.weight
INFO - encoder._module.forward_layer_2.state_linearity.bias
INFO - encoder._module.backward_layer_2.input_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.weight
INFO - encoder._module.backward_layer_2.state_linearity.bias
INFO - _feedforward._linear_layers.0.weight
INFO - _feedforward._linear_layers.0.bias
INFO - _feedforward._linear_layers.1.weight
INFO - _feedforward._linear_layers.1.bias
INFO - _feedforward._linear_layers.2.weight
INFO - _feedforward._linear_layers.2.bias
INFO - _feedforward._linear_layers.3.weight
INFO - _feedforward._linear_layers.3.bias
INFO - _feedforward._linear_layers.4.weight
INFO - _feedforward._linear_layers.4.bias
INFO - _feedforward._linear_layers.5.weight
INFO - _feedforward._linear_layers.5.bias
INFO - _feedforward._linear_layers.6.weight
INFO - _feedforward._linear_layers.6.bias
INFO - tag_projection_layer._module.weight
INFO - tag_projection_layer._module.bias
INFO - crf.transitions
INFO - trainer.patience = 10
INFO - trainer.validation_metric = +f1-measure-overall
INFO - trainer.shuffle = False
INFO - trainer.num_epochs = 200
INFO - trainer.cuda_device = -1
INFO - trainer.grad_norm = 1
INFO - trainer.grad_clipping = None
INFO - trainer.learning_rate_scheduler = None
INFO - trainer.momentum_scheduler = None
INFO - trainer.optimizer.type = adam
INFO - trainer.optimizer.parameter_groups = None
INFO - Number of trainable parameters: 1007781
INFO - trainer.optimizer.infer_type_and_cast = True
INFO - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
INFO - CURRENTLY DEFINED PARAMETERS: 
INFO - trainer.optimizer.lr = 0.007
INFO - instantiating registered subclass adam of <class 'allennlp.training.optimizers.Optimizer'>
INFO - trainer.num_serialized_models_to_keep = 70
INFO - trainer.keep_serialized_model_every_num_seconds = None
INFO - trainer.model_save_interval = None
INFO - trainer.summary_interval = 100
INFO - trainer.histogram_interval = 10
INFO - trainer.should_log_parameter_statistics = True
INFO - trainer.should_log_learning_rate = False
INFO - trainer.log_batch_size_period = None
INFO - Beginning training.
INFO - Epoch 0/199
INFO - Peak CPU memory usage MB: 2384.152
INFO - Training
INFO - Validating
INFO -                        Training |  Validation
INFO - accuracy           |     0.203  |     0.161
INFO - accuracy3          |     0.203  |     0.161
INFO - f1-measure-overall |     0.003  |     0.000
INFO - loss               |  2461.388  |  1337.643
INFO - cpu_memory_MB      |  2384.152  |       N/A
INFO - recall-overall     |     0.003  |     0.000
INFO - precision-overall  |     0.004  |     0.000
INFO - Best validation performance so far. Copying weights to './output/experiment_configs/elmo_nym_lstm3_feedforward4_crf_straight.config//best.th'.
INFO - Epoch duration: 0:10:26.233199
INFO - Estimated training time remaining: 1 day, 10:37:00
INFO - Epoch 1/199
INFO - Peak CPU memory usage MB: 23816.044
INFO - Training
INFO - Validating
